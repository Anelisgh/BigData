{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Obiceiurile studenților și performanța academică"
      ],
      "metadata": {
        "id": "wK6RahtV9qZJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. Introducere\n",
        "Setul de date [Student Habits vs Academic Performance](https://www.kaggle.com/datasets/jayaantanaath/student-habits-vs-academic-performance?resource=download) disponibil pe platforma Kaggle explorează relația dintre obiceiurile studenților și performanța lor academică.\n",
        "\n",
        "Datele pe care le vom folosi:\n",
        "\n",
        "| Coloana | Descriere |\n",
        "| --- | --- |\n",
        "| *student_id* | Identificatorul unic al studentului |\n",
        "| *age (17-24)* | Vârstă |\n",
        "| *gender (Female, Male, Other)* | Gen |\n",
        "| *study_hours_per_day (0-8.3)* | Media orelor de studiu pe zi |\n",
        "| *social_media_hours(0-7.2)* | Media orelor petrecute pe social media |\n",
        "| *netflix_hours (0-5.4)* | Media orelor petrecute pe Netflix |\n",
        "| *part_time_job (Yes/No)* | Existența unui part-time job |\n",
        "| *attendance_percentage (56-100%)* | Procentajul de prezență la cursuri |\n",
        "| *sleep_hours (3.2-10)* | Media orelor de somn pe zi |\n",
        "| *exercise_frequency (0-6)* | Frecvența exercițiilor fizice pe săptămână |\n",
        "| *exam_score (0-100)* | Scorul la examnul final |\n",
        "\n",
        "În cadrul acestui proiect vom analiza cum stilul de viață al studenților (precum timpul petrecut în fața ecranului, prezența la cursuri, somnul și activitatea fizică) le afectează performanța academică.\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "v6qzLHTX189b"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Începem prin a încărca și vizualiza datele din Kaggle"
      ],
      "metadata": {
        "id": "kNqE9ArtDiMv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import kagglehub\n",
        "from pyspark.sql import SparkSession\n",
        "\n",
        "# Descărcăm dataset-ul\n",
        "path = kagglehub.dataset_download(\"jayaantanaath/student-habits-vs-academic-performance\")\n",
        "\n",
        "# Creăm sesiunea\n",
        "spark = SparkSession.builder.appName('Habits').getOrCreate()\n",
        "\n",
        "# Încarcăm fișierul CSV din Kaggle\n",
        "df = spark.read.option(\"header\", True).csv(path + \"/student_habits_performance.csv\")\n",
        "\n",
        "# Afișăm primele rânduri\n",
        "df.show(3)\n",
        "\n",
        "# Statistici descriptive pentru a înțelege mai bine datele\n",
        "df.describe().show()"
      ],
      "metadata": {
        "id": "EDTX96vMDmLX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "88eecbb3-d2e5-44c2-f5c7-254aaf46e772"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------+---+------+-------------------+------------------+-------------+-------------+---------------------+-----------+------------+------------------+------------------------+----------------+--------------------+-----------------------------+----------+\n",
            "|student_id|age|gender|study_hours_per_day|social_media_hours|netflix_hours|part_time_job|attendance_percentage|sleep_hours|diet_quality|exercise_frequency|parental_education_level|internet_quality|mental_health_rating|extracurricular_participation|exam_score|\n",
            "+----------+---+------+-------------------+------------------+-------------+-------------+---------------------+-----------+------------+------------------+------------------------+----------------+--------------------+-----------------------------+----------+\n",
            "|     S1000| 23|Female|                0.0|               1.2|          1.1|           No|                 85.0|        8.0|        Fair|                 6|                  Master|         Average|                   8|                          Yes|      56.2|\n",
            "|     S1001| 20|Female|                6.9|               2.8|          2.3|           No|                 97.3|        4.6|        Good|                 6|             High School|         Average|                   8|                           No|     100.0|\n",
            "|     S1002| 21|  Male|                1.4|               3.1|          1.3|           No|                 94.8|        8.0|        Poor|                 1|             High School|            Poor|                   1|                           No|      34.3|\n",
            "+----------+---+------+-------------------+------------------+-------------+-------------+---------------------+-----------+------------+------------------+------------------------+----------------+--------------------+-----------------------------+----------+\n",
            "only showing top 3 rows\n",
            "\n",
            "+-------+----------+-----------------+------+-------------------+------------------+------------------+-------------+---------------------+------------------+------------+------------------+------------------------+----------------+--------------------+-----------------------------+------------------+\n",
            "|summary|student_id|              age|gender|study_hours_per_day|social_media_hours|     netflix_hours|part_time_job|attendance_percentage|       sleep_hours|diet_quality|exercise_frequency|parental_education_level|internet_quality|mental_health_rating|extracurricular_participation|        exam_score|\n",
            "+-------+----------+-----------------+------+-------------------+------------------+------------------+-------------+---------------------+------------------+------------+------------------+------------------------+----------------+--------------------+-----------------------------+------------------+\n",
            "|  count|      1000|             1000|  1000|               1000|              1000|              1000|         1000|                 1000|              1000|        1000|              1000|                    1000|            1000|                1000|                         1000|              1000|\n",
            "|   mean|      NULL|           20.498|  NULL|             3.5501| 2.505500000000002|1.8197000000000014|         NULL|    84.13170000000002| 6.470099999999999|        NULL|             3.042|                    NULL|            NULL|               5.438|                         NULL| 69.60150000000003|\n",
            "| stddev|      NULL|2.308099504640848|  NULL|  1.468889930399016| 1.172422417187732|1.0751175692861632|         NULL|    9.399246296429354|1.2263767732593391|        NULL|2.0254230023228095|                    NULL|            NULL|  2.8475014072453537|                         NULL|16.888563921818257|\n",
            "|    min|     S1000|               17|Female|                0.0|               0.0|               0.0|           No|                100.0|              10.0|        Fair|                 0|                Bachelor|         Average|                   1|                           No|             100.0|\n",
            "|    max|     S1999|               24| Other|                8.3|               7.2|               5.4|          Yes|                 99.8|               9.8|        Poor|                 6|                    None|            Poor|                   9|                          Yes|              99.9|\n",
            "+-------+----------+-----------------+------+-------------------+------------------+------------------+-------------+---------------------+------------------+------------+------------------+------------------------+----------------+--------------------+-----------------------------+------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2.1. Procesarea datelor"
      ],
      "metadata": {
        "id": "RBDLhhR5HXYA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Utilizăm dataframe pentru a păstra doar coloanele care ne interesează."
      ],
      "metadata": {
        "id": "0R7l4asCKSHD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# selectăm coloanele\n",
        "columns = [\"student_id\", \"age\", \"gender\", \"study_hours_per_day\", \"social_media_hours\", \"netflix_hours\", \"part_time_job\", \"attendance_percentage\", \"sleep_hours\", \"exercise_frequency\", \"exam_score\"]\n",
        "# le extragem\n",
        "df_columns = df.select(columns)\n",
        "# verificăm\n",
        "df_columns.show(3)"
      ],
      "metadata": {
        "id": "m__FzAlDIxXf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "63ccaed2-c01b-492d-f64e-13bc5dac3bbe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------+---+------+-------------------+------------------+-------------+-------------+---------------------+-----------+------------------+----------+\n",
            "|student_id|age|gender|study_hours_per_day|social_media_hours|netflix_hours|part_time_job|attendance_percentage|sleep_hours|exercise_frequency|exam_score|\n",
            "+----------+---+------+-------------------+------------------+-------------+-------------+---------------------+-----------+------------------+----------+\n",
            "|     S1000| 23|Female|                0.0|               1.2|          1.1|           No|                 85.0|        8.0|                 6|      56.2|\n",
            "|     S1001| 20|Female|                6.9|               2.8|          2.3|           No|                 97.3|        4.6|                 6|     100.0|\n",
            "|     S1002| 21|  Male|                1.4|               3.1|          1.3|           No|                 94.8|        8.0|                 1|      34.3|\n",
            "+----------+---+------+-------------------+------------------+-------------+-------------+---------------------+-----------+------------------+----------+\n",
            "only showing top 3 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Curățarea datelor\n",
        "Ștergem rândurile cu valori nule (NULL) sau goale (\"\", \" \"), deoarece acestea pot afecta analizele ulterioare."
      ],
      "metadata": {
        "id": "hFBXEEBafMg3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "initial_count = df_columns.count()\n",
        "print(f\"Numărul inițial de rânduri: {initial_count}\")\n",
        "\n",
        "# Ștergem rândurile ce conțin NULL\n",
        "df_fara_null = df_columns.na.drop(how=\"any\")\n",
        "randuri_null = df_fara_null.count()\n",
        "nr_randuri_null = initial_count - randuri_null\n",
        "print(f\"Au fost găsite {nr_randuri_null} rânduri NULL\")\n",
        "\n",
        "from pyspark.sql.functions import trim, col\n",
        "\n",
        "# Ștergem rânduri goale\n",
        "df_curat = df_fara_null\n",
        "for col_name in columns:\n",
        "  # Aplicăm ștergerea doar pe coloanele de tip String, altfel pentru cele de alt tip se va genera o eroare\n",
        "  if str(df_fara_null.schema[col_name].dataType) == \"StringType\":\n",
        "    # Eliminăm rândurile în care valoarea este un șir gol după eliminarea spațiilor\n",
        "      df_curat = df_curat.filter(trim(col(col_name)) != \"\")\n",
        "\n",
        "final_count = df_curat.count()\n",
        "nr_coloane_goale = initial_count - final_count\n",
        "print(f\"Au fost găsite {nr_coloane_goale} rânduri goale\")\n",
        "\n",
        "nr_randuri_curatate = nr_randuri_null + nr_coloane_goale\n",
        "\n",
        "if nr_randuri_curatate == 0:\n",
        "  print(\"Datele sunt curate!\")\n",
        "  df = df_columns\n",
        "else:\n",
        "  print(f\"Au fost curățate {nr_randuri_curatate} rânduri în total\")\n",
        "  df = df_curat\n",
        "# !În continuare putem folosi \"df\" atunci când ne referim la dataframe-ul nostru"
      ],
      "metadata": {
        "id": "IZ22u5bgKaEW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5350422f-8f39-47a5-bf5d-4d968e71769c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Numărul inițial de rânduri: 1000\n",
            "Au fost găsite 0 rânduri NULL\n",
            "Au fost găsite 0 rânduri goale\n",
            "Datele sunt curate!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Adăugăm o nouă coloană *screen_time*, care reprezintă media artimetică dintre orele petrecute pe social media (\"social_media_hours\") și orele petrecute pe Netflix (\"netflix_hours\"). Acestă modificare este necesară, deoarece obiectivul nostru nu este să diferențiem platformele utilizate, ci de a analiza timpul petrecut online în raport cu notele obținute."
      ],
      "metadata": {
        "id": "hij6R7xTKZdF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# adăugăm și calculăm noua coloană\n",
        "df = df.withColumn(\n",
        "    \"screen_time\",\n",
        "    (col(\"social_media_hours\") + col(\"netflix_hours\")) / 2\n",
        ")\n",
        "\n",
        "# eliminăm coloanele care nu ne mai sunt necesare\n",
        "df = df.drop(\"social_media_hours\", \"netflix_hours\")\n",
        "\n",
        "# afișăm noul dataframe\n",
        "df.show(3)"
      ],
      "metadata": {
        "id": "Jj-Sz5yb7f69",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f64a23c8-2ef7-44ab-9ed5-e20e65ec4c54"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------+---+------+-------------------+-------------+---------------------+-----------+------------------+----------+-----------+\n",
            "|student_id|age|gender|study_hours_per_day|part_time_job|attendance_percentage|sleep_hours|exercise_frequency|exam_score|screen_time|\n",
            "+----------+---+------+-------------------+-------------+---------------------+-----------+------------------+----------+-----------+\n",
            "|     S1000| 23|Female|                0.0|           No|                 85.0|        8.0|                 6|      56.2|       1.15|\n",
            "|     S1001| 20|Female|                6.9|           No|                 97.3|        4.6|                 6|     100.0|       2.55|\n",
            "|     S1002| 21|  Male|                1.4|           No|                 94.8|        8.0|                 1|      34.3|        2.2|\n",
            "+----------+---+------+-------------------+-------------+---------------------+-----------+------------------+----------+-----------+\n",
            "only showing top 3 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2.2. Grupări și agregări de date"
      ],
      "metadata": {
        "id": "oTbc9Gc2Zt-k"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Verificăm dacă există o legătură între statusul jobului part-time și notele finale**\n",
        "\n",
        "Am grupat studenții după coloana *part_time_job* și am calculat media notelor la examen și număr studenților din fiecare categorie."
      ],
      "metadata": {
        "id": "2LPPmIOWZ22o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import avg, count, round\n",
        "# DataFrame\n",
        "df_job = df.groupBy(\"part_time_job\").agg(\n",
        "    round(avg(\"exam_score\"), 2).alias(\"avg_score\"),\n",
        "    count(\"student_id\").alias(\"number_of_students\")).orderBy(\"avg_score\").show()"
      ],
      "metadata": {
        "id": "wYxCqq2CaQLm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d377fd1e-c080-44c4-b942-8af82257458c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------------+---------+------------------+\n",
            "|part_time_job|avg_score|number_of_students|\n",
            "+-------------+---------+------------------+\n",
            "|          Yes|    68.74|               215|\n",
            "|           No|    69.84|               785|\n",
            "+-------------+---------+------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Deși putem observa o diferență de 1.1 (68.74 comparativ cu 69.84) nu este suficientă pentru a concluziona dacă existența unui job part-time are o influență negativă asupra notelor.\n",
        "Astfel, în continuare, vom analiza dacă și genul studentului influențează relația."
      ],
      "metadata": {
        "id": "HF1kjw8vmzHa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Spark SQL\n",
        "# Creăm o vedere temporară pentru a putea folosi SQL\n",
        "df.createOrReplaceTempView(\"students\")\n",
        "\n",
        "df_job_gender = spark.sql(\"\"\"\n",
        "          SELECT gender, part_time_job, ROUND(AVG(exam_score), 2) as avg_score\n",
        "          FROM students\n",
        "          GROUP BY gender, part_time_job\n",
        "          ORDER BY part_time_job, gender\n",
        "\"\"\").show()"
      ],
      "metadata": {
        "id": "gPcQJyeHrHlx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fb0baaf5-e6e9-49af-8f08-5943a7a0b3c5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------+-------------+---------+\n",
            "|gender|part_time_job|avg_score|\n",
            "+------+-------------+---------+\n",
            "|Female|           No|    69.63|\n",
            "|  Male|           No|    69.82|\n",
            "| Other|           No|    72.58|\n",
            "|Female|          Yes|     70.2|\n",
            "|  Male|          Yes|    67.85|\n",
            "| Other|          Yes|    64.48|\n",
            "+------+-------------+---------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Observăm că efectul unui job part-time variază în funcție de gen. Femeile au tendința de a avea un scor mediu mai mare cu 0.57 puncte atunci când lucrează, în timp ce bărbații și persoanele cu alt tip de gen au scoruri mai mici cu 1.97, respectiv 8.1 puncte.\n",
        "\n",
        "Prin urmare, job-ul part-time nu are un efect uniform, depinzând de gen."
      ],
      "metadata": {
        "id": "CH-x1NfDtRvt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. Metode ML"
      ],
      "metadata": {
        "id": "n3vp6hEWw7Lx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 3.1 Regresia Liniară\n",
        "Presupunem că dorim să prezicem nota la examen în funcție de 4 factori:\n",
        "- timpul pe care studentul îl petrece învățând;\n",
        "- orele de somn;\n",
        "- timpul petrecut în fața ecranelor (cu scopul divertismentului);\n",
        "- prezența la cursuri.\n",
        "\n",
        "Motivele pentru care am ales *regresia liniară*:\n",
        "- scopul este de a face o predicție numerică;\n",
        "- este un model adecvat pentru a prezenta relațiile liniare dintre variabila dependentă (*exam_score*) și variabilele independente (*study_hours_per_day, screen_time, sleep_hours, attendance_percentage*);\n",
        "- rezultatul este ușor de interpretat.\n"
      ],
      "metadata": {
        "id": "BP_kxEpmHgXu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.ml.feature import VectorAssembler\n",
        "from pyspark.ml.regression import LinearRegression\n",
        "from pyspark.sql.functions import col\n",
        "from pyspark.sql.types import DoubleType\n",
        "\n",
        "# Coloanele pe care dorim să le folosim sunt în format String, astfel va trebui să le convertim în Double\n",
        "df = df.withColumn(\"study_hours_per_day\", col(\"study_hours_per_day\").cast(DoubleType()))\n",
        "df = df.withColumn(\"sleep_hours\", col(\"sleep_hours\").cast(DoubleType()))\n",
        "df = df.withColumn(\"screen_time\", col(\"screen_time\").cast(DoubleType()))\n",
        "df = df.withColumn(\"attendance_percentage\", col(\"attendance_percentage\").cast(DoubleType()))\n",
        "df = df.withColumn(\"exam_score\", col(\"exam_score\").cast(DoubleType()))\n",
        "\n",
        "# Combinăm mai multe coloane într-una singură (features), deoarece modelele de ML nu acceptă mai multe\n",
        "assembler = VectorAssembler(inputCols=[\"study_hours_per_day\", \"screen_time\", \"sleep_hours\", \"attendance_percentage\"],\n",
        "                            outputCol=\"features\")\n",
        "\n",
        "# Aplicăm assembler-ul pe df-ul nostru\n",
        "output = assembler.transform(df)\n",
        "\n",
        "# Selectăm coloanele necesare (x și y)\n",
        "final_data = output.select(\"features\", \"exam_score\")\n",
        "\n",
        "# Împărțim datele în train și test\n",
        "train_data, test_data = final_data.randomSplit([0.7, 0.3], seed=42)\n",
        "\n",
        "# Inițializăm modelul\n",
        "lr = LinearRegression(featuresCol=\"features\", labelCol=\"exam_score\")\n",
        "# Și îl antrenăm\n",
        "lr_model = lr.fit(train_data)\n",
        "\n",
        "print(\"Interpretarea datelor\")\n",
        "# Interpretăm coeficienții și intercept-ul\n",
        "coeffs = [f\"{coef:.2f}\" for coef in lr_model.coefficients]\n",
        "print(\"\")\n",
        "print(f\"Dacă un student:\")\n",
        "print(f\"- învață cu o oră mai mult pe zi, scorul crește cu {coeffs[0]}\")\n",
        "print(f\"- petrece o oră în plus în fața ecranului, scorul scade cu {coeffs[1]}\")\n",
        "print(f\"- doarme cu o oră în plus, scorul crește cu {coeffs[2]}\")\n",
        "print(f\"- are un procent în plus la prezență, scorul crește cu {coeffs[3]}\")\n",
        "print(f\"Intercept: {lr_model.intercept:.2f} (scorul studentului dacă nu ar face nimic din cele de mai sus)\")\n",
        "\n",
        "# Evaluăm modelul\n",
        "test_results = lr_model.evaluate(test_data)\n",
        "print(f\"RMSE: modelul greșește în medie cu {test_results.rootMeanSquaredError:.2f} puncte față de valorile reale\")\n",
        "r2_percentage = test_results.r2 * 100\n",
        "print(f\"R2: {r2_percentage:.2f}% din variația notelor poate fi explicată de variabilele utilizate\")\n",
        "\n",
        "# Predicții\n",
        "print(\"\\nPredicții\")\n",
        "unlabeled_data = test_data.select(\"features\")\n",
        "predictions = lr_model.transform(test_data)\n",
        "predictions.select(\"features\", \"prediction\", \"exam_score\").show(10)\n",
        "print(\"Diferența dintre valoarea reală și predicția modelului\")\n",
        "test_results.residuals.show(10)\n"
      ],
      "metadata": {
        "id": "IV2HeHRH1f4-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a56f9d69-f373-461f-cbf9-4844bffc2669"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Interpretarea datelor\n",
            "\n",
            "Dacă un student:\n",
            "- învață cu o oră mai mult pe zi, scorul crește cu 9.39\n",
            "- petrece o oră în plus în fața ecranului, scorul scade cu -5.08\n",
            "- doarme cu o oră în plus, scorul crește cu 1.79\n",
            "- are un procent în plus la prezență, scorul crește cu 0.13\n",
            "Intercept: 25.51 (scorul studentului dacă nu ar face nimic din cele de mai sus)\n",
            "RMSE: modelul greșește în medie cu 8.57 puncte față de valorile reale\n",
            "R2: 77.28% din variația notelor poate fi explicată de variabilele utilizate\n",
            "\n",
            "Predicții\n",
            "+-------------------+------------------+----------+\n",
            "|           features|        prediction|exam_score|\n",
            "+-------------------+------------------+----------+\n",
            "|[0.0,1.15,8.0,85.0]| 44.60155289472823|      56.2|\n",
            "| [0.0,2.2,5.8,93.4]| 36.39129185080092|      26.7|\n",
            "|[0.0,2.55,5.7,89.5]|  33.9482085763249|      31.1|\n",
            "|[0.0,2.65,3.8,85.6]|29.557211027967256|      30.5|\n",
            "| [0.1,0.6,7.6,78.7]| 46.82966265520549|      53.4|\n",
            "| [0.2,2.6,7.0,77.9]| 36.44549677459311|      31.5|\n",
            "|[0.3,2.25,8.3,77.5]| 41.43468594389006|      36.1|\n",
            "| [0.5,1.3,5.8,86.4]|44.781113292336876|      45.0|\n",
            "| [0.5,2.7,7.7,81.0]| 40.39519879449194|      30.2|\n",
            "|[0.6,3.05,5.2,79.9]| 34.95278461811432|      18.4|\n",
            "+-------------------+------------------+----------+\n",
            "only showing top 10 rows\n",
            "\n",
            "Diferența dintre valoarea reală și predicția modelului\n",
            "+-------------------+\n",
            "|          residuals|\n",
            "+-------------------+\n",
            "| 11.598447105271774|\n",
            "|  -9.69129185080092|\n",
            "|-2.8482085763249003|\n",
            "| 0.9427889720327443|\n",
            "|   6.57033734479451|\n",
            "|  -4.94549677459311|\n",
            "| -5.334685943890058|\n",
            "|  0.218886707663124|\n",
            "| -10.19519879449194|\n",
            "|-16.552784618114323|\n",
            "+-------------------+\n",
            "only showing top 10 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3.2 Regresie Logistică\n",
        "Presupunem că dorim să precizăm probabilitatea ca un student sa promoveze examenul (nota >= 5), pe bază a doi factori:\n",
        "* timpul mediu petrecut învățând;\n",
        "* procentul de prezență la cursuri.\n",
        "\n",
        "Motivele pentru care am ales regresia logistică:\n",
        "* este potrivit pentru clasificarea binară (1 - dacă studentul a promovat, 0 - dacă nu);\n",
        "* ușor de implementat, interpretat și antrenat.\n",
        "\n"
      ],
      "metadata": {
        "id": "hxASEWFqRUG4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import when\n",
        "from pyspark.ml.classification import LogisticRegression\n",
        "from pyspark.ml.evaluation import BinaryClassificationEvaluator, MulticlassClassificationEvaluator\n",
        "\n",
        "# Creăm o nouă coloană passed_exam care va conține 1 daca nota este 5 sau mai mare sau 0 daca este mai mică de 5\n",
        "df = df.withColumn(\"passed_exam\", when(col(\"exam_score\") >= 50, 1).otherwise(0))\n",
        "\n",
        "# Combinăm mai multe coloane într-una singură (features), deoarece modelele de ML nu acceptă mai multe\n",
        "assembler = VectorAssembler(inputCols=[\"study_hours_per_day\", \"attendance_percentage\"],\n",
        "                            outputCol=\"features\")\n",
        "\n",
        "# Aplicăm assembler-ul pe df-ul nostru\n",
        "output = assembler.transform(df)\n",
        "\n",
        "# Selectăm coloanele necesare (x și y)\n",
        "final_data = output.select(\"features\", \"passed_exam\")\n",
        "\n",
        "# Împărțim datele în train și test\n",
        "train_data, test_data = final_data.randomSplit([0.7, 0.3], seed=42)\n",
        "\n",
        "# Inițializăm modelul\n",
        "lr = LogisticRegression(featuresCol=\"features\", labelCol=\"passed_exam\")\n",
        "# Și îl antrenăm pe setul de date de antrenament\n",
        "lr_model = lr.fit(train_data)\n",
        "\n",
        "# Evaluăm modelul pe datele de test\n",
        "results = lr_model.evaluate(test_data)\n",
        "\n",
        "# Predicțiile pentru model\n",
        "predictions = lr_model.transform(test_data)\n",
        "\n",
        "# Evaluăm eficiența folosind AUC (Area under the ROC Curve)\n",
        "evaluator_auc = BinaryClassificationEvaluator(rawPredictionCol=\"prediction\", labelCol=\"passed_exam\")\n",
        "# AUC - cât de bine diferențiază modelul între studenții care au trecut și cei care nu\n",
        "auc = evaluator_auc.evaluate(predictions)\n",
        "\n",
        "multi_evaluator = MulticlassClassificationEvaluator(labelCol=\"passed_exam\", predictionCol=\"prediction\")\n",
        "\n",
        "# Calculăm acuratețea - proporția de predicții corecte (adică cât de des are dreptate modelul)\n",
        "accuracy = multi_evaluator.evaluate(predictions, {multi_evaluator.metricName: \"accuracy\"})\n",
        "# Calculăm precizia - proporția de valori prezise ca fiind pozitive și care sunt într-adevăr pozitive (adică precizia penalizează predicțiile greșite ca pozitive)\n",
        "precision = multi_evaluator.evaluate(predictions, {multi_evaluator.metricName: \"weightedPrecision\"})\n",
        "# Calculăm sensibilitatea - proporția de valori pozitive corect identificate (adică sensibilitatea penalizează ratările pozitive)\n",
        "recall = multi_evaluator.evaluate(predictions, {multi_evaluator.metricName: \"weightedRecall\"})\n",
        "# Calculăm F1 - media armonică dintre precizie și sensibilitate care echilibrează greșelile de tip fals pozitiv și fals negativ\n",
        "f1_score = 2 * (precision * recall) / (precision + recall)\n",
        "\n",
        "print(f\"Modelul prezice corect rezultatul în {accuracy * 100:.2f}% din cazuri. (Acuratețe)\")\n",
        "print(f\"Dintre toate cazurile pe care modelul le-a prezis ca fiind promovate au fost corecte {precision * 100:.2f}%. (Precizie)\")\n",
        "print(f\"Indetifică {recall * 100:.2f}% din studenții care au trecut cu adevărat. (Sensibilitate)\")\n",
        "print(f\"Capacitatea de a distinge între promovări și restanțe este de {auc * 100:.2f}% (ROC-AUC)\")\n",
        "print(f\"Echilibrul dintre precizie și sensibilitate: {f1_score * 100:.2f}% (Scorul F1)\")\n",
        "\n",
        "#Calculăm coeficienții și intercept-ul\n",
        "coeffs = lr_model.coefficients\n",
        "intercept = lr_model.intercept\n",
        "print(\"\\nCoeficienții indică impactul fiecărei variabile asupra șansei de promovare.\")\n",
        "# log-odds - șansa de promovare, folosită de model pentru a calcula probabilitatea\n",
        "print(\"Interpretarea coeficienților (log-odds):\")\n",
        "print(f\"Fiecare oră suplimentară de studiu crește log-odds-ul promovării cu {coeffs[0]:.2f}\")\n",
        "print(f\"Fiecare procent suplimentar de prezență crește log-odds-ul promovării cu {coeffs[1]:.2f}\")\n",
        "print(f\"Intercept ({intercept:.2f}): șansa inițială de promovare când toate variabilele sunt zero\")\n",
        "\n"
      ],
      "metadata": {
        "id": "eIMAP2KJ4n90",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e0c4a397-7868-4537-e88f-9fcc7f1f215f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Modelul prezice corect rezultatul în 89.45% din cazuri. (Acuratețe)\n",
            "Dintre toate cazurile pe care modelul le-a prezis ca fiind promovate au fost corecte 89.86%. (Precizie)\n",
            "Indetifică 89.45% din studenții care au trecut cu adevărat. (Sensibilitate)\n",
            "Capacitatea de a distinge între promovări și restanțe este de 78.97% (ROC-AUC)\n",
            "Echilibrul dintre precizie și sensibilitate: 89.66% (Scorul F1)\n",
            "\n",
            "Coeficienții indică impactul fiecărei variabile asupra șansei de promovare.\n",
            "Interpretarea coeficienților (log-odds):\n",
            "Fiecare oră suplimentară de studiu crește log-odds-ul promovării cu 2.04\n",
            "Fiecare procent suplimentar de prezență crește log-odds-ul promovării cu 0.04\n",
            "Intercept (-6.51): șansa inițială de promovare când toate variabilele sunt zero\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4. Data Pipeline\n",
        "Am utilizat data pipeline-uri în mai multe locuri în codurile de mai sus.\n",
        "Spre exemplu, atunci cand am transformat valorile din string in DoubleType sau când am combinat mai multe coloane într-una singură cu VectorAssembler."
      ],
      "metadata": {
        "id": "Gi97t5hmyj3v"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5. UDF\n",
        "Vom defini o funcție UDF care convertește genul din variabilele calitative în formă numerică. Astfel, \"Male\" va deveni 0, \"Female\" 1 și \"Other\" 2."
      ],
      "metadata": {
        "id": "H7ojqvHTA2ai"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import udf\n",
        "from pyspark.sql.types import IntegerType\n",
        "# Funcția care face transformarea\n",
        "def gender_to_int(g):\n",
        "    if g == \"Female\":\n",
        "        return 1\n",
        "    elif g == \"Male\":\n",
        "        return 0\n",
        "    else:\n",
        "        return 2\n",
        "# Definim funcția UDF de tip Integer\n",
        "gender_udf = udf(gender_to_int, IntegerType())\n",
        "# Aplicăm UDF-ul pentru a crea o nouă coloană \"gender_num\"\n",
        "df = df.withColumn(\"gender_num\", gender_udf(col(\"gender\")))\n",
        "# Verificăm modificările\n",
        "df.select(\"gender\", \"gender_num\").show(5)\n",
        "\n",
        "df.show(5)"
      ],
      "metadata": {
        "id": "onfgyIa8alF2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dd2ff6f9-33cd-4ba5-9c11-683b7ba4cfc5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------+----------+\n",
            "|gender|gender_num|\n",
            "+------+----------+\n",
            "|Female|         1|\n",
            "|Female|         1|\n",
            "|  Male|         0|\n",
            "|Female|         1|\n",
            "|Female|         1|\n",
            "+------+----------+\n",
            "only showing top 5 rows\n",
            "\n",
            "+----------+---+------+-------------------+-------------+---------------------+-----------+------------------+----------+-----------+-----------+----------+\n",
            "|student_id|age|gender|study_hours_per_day|part_time_job|attendance_percentage|sleep_hours|exercise_frequency|exam_score|screen_time|passed_exam|gender_num|\n",
            "+----------+---+------+-------------------+-------------+---------------------+-----------+------------------+----------+-----------+-----------+----------+\n",
            "|     S1000| 23|Female|                0.0|           No|                 85.0|        8.0|                 6|      56.2|       1.15|          1|         1|\n",
            "|     S1001| 20|Female|                6.9|           No|                 97.3|        4.6|                 6|     100.0|       2.55|          1|         1|\n",
            "|     S1002| 21|  Male|                1.4|           No|                 94.8|        8.0|                 1|      34.3|        2.2|          0|         0|\n",
            "|     S1003| 23|Female|                1.0|           No|                 71.0|        9.2|                 4|      26.8|       2.45|          0|         1|\n",
            "|     S1004| 19|Female|                5.0|           No|                 90.9|        4.9|                 3|      66.4|       2.45|          1|         1|\n",
            "+----------+---+------+-------------------+-------------+---------------------+-----------+------------------+----------+-----------+-----------+----------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 6. Metoda DL și optimizarea hiperparametrilor\n"
      ],
      "metadata": {
        "id": "QipGo_0zdFtv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ne propunem să construim un model de machine learning care va învăța să prezică dacă un student va promova sau nu un examen, pe baza factorilor precum: vârsta, genul, timpul petrecut zilnic învățând, în fața ecranului sau dormind, dar și procentul de prezență la cursuri și frecvența activității fizice.\n",
        "\n",
        "Am ales ca metodă Multi-Layer Perceptron (MLP) deoarece:\n",
        "* este versatil, fiind perfect pentru date tabulare;\n",
        "* este nonlinear, deci poate modela relațiile complexe între factorii care influențeză nota finală;\n",
        "* permite optimizarea ușoară a hiperparametrilor prin GridSearchCV, testând diferite combinații de neuroni."
      ],
      "metadata": {
        "id": "pUkBt0a5pImA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import scikeras\n",
        "import tensorflow\n",
        "from pyspark.sql.functions import col\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout, Input\n",
        "from scikeras.wrappers import KerasClassifier\n",
        "\n",
        "# Alegem coloanele relevante\n",
        "cols = [\"age\", \"gender_num\", \"study_hours_per_day\", \"screen_time\", \"attendance_percentage\", \"sleep_hours\", \"exercise_frequency\", \"passed_exam\"]\n",
        "df_cols = df.select(*cols)\n",
        "\n",
        "# Convertim din spark dataframe în pandas, pentru ca tensorflow nu poate utiliza spark\n",
        "pandas_df = df_cols.toPandas().astype(float)\n",
        "\n",
        "# Pregătim datele, x - datele de intrare, y - dacă a trecut examenul (1) sau nu (0)\n",
        "X = pandas_df.drop(\"passed_exam\", axis=1)\n",
        "y = pandas_df['passed_exam'].astype(int)\n",
        "\n",
        "# Standardizăm datele și le împărțim în antrenare 80% și testare 20%\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "# în timp ce random_state face împărțirea aleatorie să fie mereu aceeași, stratify păstrează proporția claselor\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42, stratify=y)\n",
        "\n",
        "# Creăm o UDF care construiește rețeaua neuronală\n",
        "# adam = algoritm care învață din greșeli\n",
        "def create_model(optimizer='adam', dropout_rate=0.2, units1=64, units2=32):\n",
        "  model = Sequential([ # straturile sunt aranjate unul după altul, secvențial\n",
        "      Input(shape=(X_train.shape[1],)), # primul start de intrare care va primi numărul de coloane din X_train\n",
        "      Dense(units1, activation='relu'), # relu = Rectified Linear Unit. ce face? dacă input-ul este un număr pozitiv îl va lăsa să treacă, dar dacă este negativ îl va transforma în 0\n",
        "      Dropout(dropout_rate), # oprim aleatoriu 20% din neuroni. Dacă memorează prea bine datele de antrenare nu va fucționa și pe unele noi\n",
        "      Dense(units2, activation='relu'),\n",
        "      Dropout(dropout_rate),\n",
        "      Dense(1, activation='sigmoid') # folosim doar un neuron, pentru ca vrem să știm dacă studentul trece sau nu (1 sau 0), iar sigmoid face această transformare\n",
        "  ])\n",
        "  # compilăm modelul și măsurăm acuratețea, adică procentul de răspunsuri corecte\n",
        "  model.compile(optimizer = optimizer, loss = 'binary_crossentropy', metrics = ['accuracy']) # binary_crossentropy = măsoară distanța dintre etichetele claselor reale și probabilitățile prezise de model\n",
        "  return model\n",
        "\n",
        "# creăm obiectul clasei KerasClassifier, pentru a putea folosi sklearn\n",
        "model = KerasClassifier(model=create_model, verbose=0)\n",
        "# creăm dicționarul parametrilor pe care vrem să îi ajustăm și transmite ca argument în GridSearchCV\n",
        "# OPTIMIZAREA HIPERPARAMETRILOR REȚELEI NEURONALE\n",
        "dict_params = { # valorile sunt transmise ca argumente în funcția create_model(), pentru a încerca diverse variante\n",
        "    'model__optimizer': ['adam', 'rmsprop'],\n",
        "    'model__dropout_rate': [0.2, 0.3],\n",
        "    'model__units1': [64, 32],\n",
        "    'model__units2': [32, 16],\n",
        "    'batch_size': [32], # câte exemple să proceseze odată\n",
        "    'epochs': [20] # de câte ori să treacă prin toate datele de antrenare\n",
        "} # Astfel, GridSearchCV poate testa toate combinațiile posibile\n",
        "# Creăm obiectul GridSearchCV\n",
        "grid = GridSearchCV(estimator=model, param_grid=dict_params, scoring='accuracy', cv=3, error_score='raise') # cv împarte datele de antrenare (X_train și y_train) în 3 părti egale\n",
        "# Executăm căutarea\n",
        "grid.fit(X_train, y_train)\n",
        "# Afișăm rezultatele\n",
        "print(\"Cele mai bune valori ale hiperparametrilor: \", grid.best_params_)\n",
        "print(\"Cel mai bun scor: \", grid.best_score_)\n",
        "\n",
        "# Evaluam modelul final pe datele de test care nu au fost folosite in GridSerchCV\n",
        "# extragem modelul cu cei mai buni hiperparametri găsiți\n",
        "best_model = grid.best_estimator_.model_\n",
        "# calculăm acuratețea finală\n",
        "accuracy = grid.best_estimator_.score(X_test, y_test) # folosim verbose=0 pentru a nu mai afișa progresul în timpul evaluării\n",
        "print(f\"Acuratețea setului de test: {accuracy:.2f}\")\n",
        "# transformăm probabilitățile, adică probabilitate mai mare de 0.5 va trece (deci 1), altfel 0\n",
        "y_pred = (best_model.predict(X_test) > 0.5).astype(int)\n",
        "print(\"Matricea de confuzie: \\n\", confusion_matrix(y_test, y_pred))\n",
        "print(\"Raportul de clasificare: \\n\", classification_report(y_test, y_pred))"
      ],
      "metadata": {
        "id": "WUbNl7DWdRnZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3d4e4571-9933-4c25-8eec-40cc4ff03eb6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cele mai bune valori ale hiperparametrilor:  {'batch_size': 32, 'epochs': 20, 'model__dropout_rate': 0.2, 'model__optimizer': 'adam', 'model__units1': 32, 'model__units2': 32}\n",
            "Cel mai bun scor:  0.9075309997841045\n",
            "Acuratețea setului de test: 0.92\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step \n",
            "Matricea de confuzie: \n",
            " [[ 12  14]\n",
            " [  2 172]]\n",
            "Raportul de clasificare: \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.46      0.60        26\n",
            "           1       0.92      0.99      0.96       174\n",
            "\n",
            "    accuracy                           0.92       200\n",
            "   macro avg       0.89      0.73      0.78       200\n",
            "weighted avg       0.92      0.92      0.91       200\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "GridSearchCV a găsit cea mai bună combinație de parametri ca fiind:\n",
        "* optimizer: Adam,\n",
        "* dropout rate: 20%,\n",
        "* 32 de neuroni în primul strat ascuns,\n",
        "* 32 în al doilea,\n",
        "* batch size: 32,\n",
        "* epochs: 20.\n",
        "\n",
        "Acuratețea finală este de 92%, deci clasifică corect 92% din studenți, fiind o performanță foarte bună.\n",
        "\n",
        "În matricea de confuzie a prezis:\n",
        "* corect că nu vor trece (TN) 12 studenți,\n",
        "* corect că vor trece (TP) 172 studenți,\n",
        "* greșit că nu vor trece, dar au trecut 2 studenți (FN),\n",
        "* greșit că vor trece, dar nu au trecut (FP) 14 studenți.\n",
        "\n",
        "Astfel, putem observa o problemă în identificarea studenților care nu au promovat.\n",
        "\n",
        "Același lucru putem observa și în raportul de clasificare: studenții care au promovat (1) sunt identificați corect în cele mai multe cazuri, dar cei care nu au promovat (0) sunt identificați în număr mult prea mic.\n",
        "\n",
        "Un motiv posibil pentru inacuratețea în cazul nepromovării este dezechilibrul dintre clase, fiindcă în datele noastre avem 174 de studenți care promovează și doar 26 care nu. Prin urmare, modelul va învăța să favorizeze clasa majoritară pentru a obține o acuratețe mai mare, în timp ce va avea o performanță slabă în detectarea cazurilor din clasa minoritară.\n",
        "\n",
        "În consecință, vom echilibra clasele prin undersampling, adică vom reduce numărul de observații din categoria majoritară pentru a obține un set balansat."
      ],
      "metadata": {
        "id": "fiahY0OPO2Io"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.utils import resample\n",
        "# Separăm clasele în 2 df-uri\n",
        "passed = pandas_df[pandas_df['passed_exam'] == 1]\n",
        "failed = pandas_df[pandas_df['passed_exam'] == 0]\n",
        "print(\"Înainte de undersampling:\")\n",
        "print(pandas_df['passed_exam'].value_counts())\n",
        "print(f\"Clasa minoritară are {len(failed)} observații\")\n",
        "# Undersampling-ul\n",
        "passed_undersampled = resample(passed, replace=False, n_samples=len(failed), random_state=42)\n",
        "undersampled_df = pd.concat([passed_undersampled, failed])\n",
        "\n",
        "# Verificăm\n",
        "print(\"După undersampling: \")\n",
        "print(undersampled_df['passed_exam'].value_counts())\n",
        "\n",
        "# Pregătim datele\n",
        "X_undersampled = undersampled_df.drop('passed_exam', axis=1)\n",
        "y_undersampled = undersampled_df['passed_exam'].astype(int)\n",
        "\n",
        "# Standardizarea și împărțirea datelor\n",
        "X_undersampled_scaled = scaler.fit_transform(X_undersampled)\n",
        "X_train_undersampled, X_test_undersampled, y_train_undersampled, y_test_undersampled = train_test_split(X_undersampled_scaled, y_undersampled, test_size=0.2, random_state=42, stratify=y_undersampled)\n",
        "\n",
        "# creăm obiectul clasei KerasClassifier\n",
        "model_undersampled = KerasClassifier(model=create_model, verbose=0)\n",
        "\n",
        "# Creăm obiectul GridSearchCV\n",
        "grid_undersampled = GridSearchCV(estimator=model_undersampled, param_grid=dict_params, scoring='accuracy', cv=3)\n",
        "# Executăm căutarea\n",
        "grid_undersampled.fit(X_train_undersampled, y_train_undersampled)\n",
        "\n",
        "# Afișăm rezultatele\n",
        "print(\"Cele mai bune valori ale hiperparametrilor: \", grid_undersampled.best_params_)\n",
        "print(\"Cel mai bun scor: \", grid_undersampled.best_score_)\n",
        "\n",
        "# Evaluam modelul final pe datele de test care nu au fost folosite in GridSearchCV\n",
        "# extragem modelul cu cei mai buni hiperparametri găsiți\n",
        "best_model_undersampled = grid_undersampled.best_estimator_.model_\n",
        "# calculăm acuratețea finală\n",
        "loss, accuracy = best_model_undersampled.evaluate(X_test_undersampled, y_test_undersampled, verbose=0) # folosim verbose=0 pentru a nu mai afișa progresul în timpul evaluării\n",
        "print(f\"Acuratețea setului de test: {accuracy:.2f}\")\n",
        "# transformăm probabilitățile, adică probabilitate mai mare de 0.5 va trece (deci 1), altfel 0\n",
        "y_pred = (best_model_undersampled.predict(X_test_undersampled) > 0.5).astype(int)\n",
        "print(\"Matricea de confuzie: \\n\", confusion_matrix(y_test_undersampled, y_pred))\n",
        "print(\"Raportul de clasificare: \\n\", classification_report(y_test_undersampled, y_pred))"
      ],
      "metadata": {
        "id": "G2WfGaz_EQn2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "37d7acbf-93a5-4a42-c445-da65ca74ba15"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Înainte de undersampling:\n",
            "passed_exam\n",
            "1.0    869\n",
            "0.0    131\n",
            "Name: count, dtype: int64\n",
            "Clasa minoritară are 131 observații\n",
            "După undersampling: \n",
            "passed_exam\n",
            "1.0    131\n",
            "0.0    131\n",
            "Name: count, dtype: int64\n",
            "Cele mai bune valori ale hiperparametrilor:  {'batch_size': 32, 'epochs': 20, 'model__dropout_rate': 0.2, 'model__optimizer': 'rmsprop', 'model__units1': 64, 'model__units2': 32}\n",
            "Cel mai bun scor:  0.8946169772256729\n",
            "Acuratețea setului de test: 0.89\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step\n",
            "Matricea de confuzie: \n",
            " [[26  1]\n",
            " [ 5 21]]\n",
            "Raportul de clasificare: \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.96      0.90        27\n",
            "           1       0.95      0.81      0.88        26\n",
            "\n",
            "    accuracy                           0.89        53\n",
            "   macro avg       0.90      0.89      0.89        53\n",
            "weighted avg       0.90      0.89      0.89        53\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Interpretarea finală**\n",
        "\n",
        "După aplicarea undersampling-ului, GridSearchCV a găsit o combinație optimă de hiperparametri similară cu modelul anterior, obținând o acuratețe de 89%, aparent mai scăzută comparativ cu modelul neechilibrat (92%), dar trebuie să avem în vedere și celelalte aspecte.\n",
        "\n",
        "În matricea de confuzie observăm o îmbunătățire considerabilă. Acesta a prezis:\n",
        "* corect că nu vor trece (TN) 26 studenți,\n",
        "* corect că vor trece (TP) 21 studenți,\n",
        "* greșit că nu va trece, dar a trecut 1 student (FP),\n",
        "* greșit că vor trece, dar nu au trecut (FN) 5 studenți.\n",
        "\n",
        "Modelul neechilibrat detecta doar 46% din studenții nepromovați, dar funcționa excelent pentru clasa majoritară (99% recall pentru promovați).\n",
        "\n",
        "Modelul echilibrat oferă o performanță potrivită pentru ambele cazuri: detectează 96% din studenții nepromovați și 81% din cei promovați.\n",
        "\n",
        "În concluzie, în ciuda faptului că acuratețea scade cu 3%, modelul echilibrat este semnificativ mai eficient în identificarea corectă a ambelor grupuri de studenți.\n",
        "\n"
      ],
      "metadata": {
        "id": "RUMH62M8Q-UR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 7. Proces de streaming\n",
        "Vom crea un sistem care să primească noi date despre studenți în timp real și să prezică dacă aceștia vor promova examenul, folosind modelul antrenat anterior."
      ],
      "metadata": {
        "id": "wTsMWyy5akaR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Definim structura datelor care vor veni prin streaming\n",
        "from pyspark.sql.types import *\n",
        "from pyspark.sql.functions import col, udf\n",
        "import time\n",
        "import shutil\n",
        "import json\n",
        "import os\n",
        "import builtins\n",
        "\n",
        "# Definim o schemă cu informațiile pe care le vom avea despre fiecare student\n",
        "schema = StructType([\n",
        "    StructField(\"age\", IntegerType(), True),\n",
        "    StructField(\"gender_num\", IntegerType(), True),\n",
        "    StructField(\"study_hours_per_day\", DoubleType(), True),\n",
        "    StructField(\"screen_time\", DoubleType(), True),\n",
        "    StructField(\"attendance_percentage\", DoubleType(), True),\n",
        "    StructField(\"sleep_hours\", DoubleType(), True),\n",
        "    StructField(\"exercise_frequency\", DoubleType(), True)])\n",
        "\n",
        "# Creăm un director temporar unde vor ajunge fișierele cu datele noi\n",
        "dir = \"/tmp/streaming\"\n",
        "# Dacă există deja îl ștergem\n",
        "if os.path.exists(dir):\n",
        "  shutil.rmtree(dir)\n",
        "# Și îl creăm din nou\n",
        "os.makedirs(dir)\n",
        "\n",
        "# Creăm o funcție pentru a folosi modelul\n",
        "def predict_student_result(age, gender_num, study_hours_per_day, screen_time, attendance_percentage, sleep_hours, exercise_frequency):\n",
        "  # Creăm un array care conține datele formatate pentru model\n",
        "  input_data = np.array([[float(age), float(gender_num), float(study_hours_per_day), float(screen_time), float(attendance_percentage), float(sleep_hours), float(exercise_frequency)]])\n",
        "  # Normalizăm datele\n",
        "  scaled_input = scaler.transform(input_data)\n",
        "  # Utilizăm modelul de machine learning antrenat anterior pentru a face predicția\n",
        "  prediction = best_model_undersampled.predict(scaled_input)[0][0]\n",
        "  # Dacă probabilitatea este mai mare de 0.5 studentul va promova\n",
        "  return \"Promovează\" if prediction > 0.5 else \"Nu promovează\", float(prediction)\n",
        "\n",
        "# Creăm un UDF care face ca funcția de mai sus să fie compatibilă cu Spark\n",
        "predict_udf = udf(predict_student_result, StructType([\n",
        "    StructField(\"result\", StringType()),\n",
        "    StructField(\"probability\", DoubleType())\n",
        "]))\n",
        "# Configurăm citirea în timp real a stream-ului\n",
        "stream_df = spark.readStream.schema(schema).json(dir)\n",
        "# Pentru fiecare rând aplicăm UDF-ul și selectăm coloanele relevante\n",
        "result_df = stream_df.withColumn(\"prediction_result\", predict_udf(col(\"age\"), col(\"gender_num\"), col(\"study_hours_per_day\"), col(\"screen_time\"), col(\"attendance_percentage\"), col(\"sleep_hours\"), col(\"exercise_frequency\"))).select(\"*\", \"prediction_result.result\", \"prediction_result.probability\")\n",
        "# Afișăm rezultatul\n",
        "query = result_df.writeStream.outputMode(\"append\").format(\"console\").start()\n",
        "\n",
        "# Creăm o funcție care simulează primirea de studenți noi la fiecare 3 secunde\n",
        "def generate_data():\n",
        "  students_generated = []\n",
        "  # Creăm 10 fișiere, adică 10 studenți\n",
        "  for i in range(10):\n",
        "    data = {\n",
        "      \"age\": int(np.random.randint(17, 25)),\n",
        "      \"gender_num\": int(np.random.randint(0, 3)),\n",
        "      \"study_hours_per_day\": float(builtins.round(np.random.uniform(1.0, 8.3), 2)),\n",
        "      \"screen_time\": float(builtins.round(np.random.uniform(0.0, 7.2), 2)),\n",
        "      \"attendance_percentage\": float(builtins.round(np.random.uniform(56.0, 100.0), 2)),\n",
        "      \"sleep_hours\": float(builtins.round(np.random.uniform(6.0, 10.0), 2)),\n",
        "      \"exercise_frequency\": float(builtins.round(np.random.uniform(0.0, 6.0), 2))}\n",
        "    # Adăugăm datele în fișier\n",
        "    with open(f\"{dir}/data_{i}.json\", 'w') as f:\n",
        "      json.dump(data, f)\n",
        "    students_generated.append(data)\n",
        "    time.sleep(3)\n",
        "  return students_generated\n",
        "students_data = generate_data()\n",
        "# Așteptăm să se procedeze toate datele\n",
        "time.sleep(20)\n",
        "# Oprim stream-ul\n",
        "query.stop()\n",
        "\n",
        "# Citim datele\n",
        "processed_data = spark.read.schema(schema).json(dir)\n",
        "# Verificăm dacă există datele\n",
        "if processed_data.count() > 0:\n",
        "  print(f\"Numărul total de studenți procesați {processed_data.count()}\")\n",
        "  # Aplicăm modelul de predicție pentru fiecare rând pentru a obține rezultatul și probabilitatea\n",
        "  analysis_df = processed_data.withColumn(\"prediction_result\", predict_udf(col(\"age\"), col(\"gender_num\"), col(\"study_hours_per_day\"), col(\"screen_time\"), col(\"attendance_percentage\"), col(\"sleep_hours\"), col(\"exercise_frequency\")))\n",
        "  # Numarăul total de înregistrări\n",
        "  total = analysis_df.count()\n",
        "  # Câți studenți au promovat\n",
        "  promovat = analysis_df.filter(col(\"prediction_result.result\") == \"Promovează\").count()\n",
        "  # Câți studenți nu au promovat\n",
        "  nu_au_promovat = analysis_df.filter(col(\"prediction_result.result\") == \"Nu promovează\").count()\n",
        "  print(f\"Total studenți: {total}\")\n",
        "  print(f\"Au promovat: {promovat}\")\n",
        "  print(f\"Nu au promovat: {nu_au_promovat}\")\n",
        "  # Afișăm pentru fiecare student valorile de input, rezultatul și probabilitatea\n",
        "  analysis_df.select(\"age\", \"gender_num\", \"study_hours_per_day\", \"sleep_hours\", \"attendance_percentage\", \"exercise_frequency\", \"prediction_result.result\", \"prediction_result.probability\").show()\n",
        "# Dacă nu există date afisăm un mesaj\n",
        "else:\n",
        "  print(\"Nu au fost găsite date pentru procesare.\")\n"
      ],
      "metadata": {
        "id": "MAOvWRcdhk5a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "be4fda98-d4c3-4721-d461-48a99bf4cacd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Numărul total de studenți procesați 10\n",
            "Total studenți: 10\n",
            "Au promovat: 7\n",
            "Nu au promovat: 3\n",
            "+---+----------+-------------------+-----------+---------------------+------------------+-------------+--------------------+\n",
            "|age|gender_num|study_hours_per_day|sleep_hours|attendance_percentage|exercise_frequency|       result|         probability|\n",
            "+---+----------+-------------------+-----------+---------------------+------------------+-------------+--------------------+\n",
            "| 24|         0|               5.45|       6.32|                67.27|              2.22|   Promovează|  0.9994384050369263|\n",
            "| 18|         1|               3.87|       9.94|                90.91|              2.56|   Promovează|  0.7588656544685364|\n",
            "| 21|         0|               5.49|       9.97|                74.91|              5.83|   Promovează|  0.9709483981132507|\n",
            "| 24|         0|               7.35|       6.69|                95.33|              3.26|   Promovează|  0.9999445676803589|\n",
            "| 24|         0|               5.74|       7.33|                68.41|              5.51|   Promovează|  0.9896321892738342|\n",
            "| 24|         0|               4.23|       8.33|                70.74|              2.07|   Promovează|  0.9962394833564758|\n",
            "| 17|         2|               4.31|       8.73|                56.62|              4.89|Nu promovează| 0.03165089711546898|\n",
            "| 24|         2|               5.83|       9.78|                 82.8|              3.63|   Promovează|  0.9951540231704712|\n",
            "| 22|         0|               1.96|        7.3|                91.39|              0.91|Nu promovează|0.020967749878764153|\n",
            "| 17|         0|                2.0|       9.63|                66.73|              4.27|Nu promovează| 0.20494677126407623|\n",
            "+---+----------+-------------------+-----------+---------------------+------------------+-------------+--------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Referințe bibliografice:\n",
        "* https://www.geeksforgeeks.org/logistic-regression-using-pyspark-python/\n",
        "* https://h2o.ai/wiki/logistic-regression/\n",
        "* https://www.geeksforgeeks.org/understanding-logistic-regression/\n",
        "* https://www.machinelearningplus.com/pyspark/pyspark-logistic-regression/\n",
        "* https://www.geeksforgeeks.org/f1-score-in-machine-learning/\n",
        "* https://www.geeksforgeeks.org/deep-learning/implementing-neural-networks-using-tensorflow/\n",
        "* https://www.geeksforgeeks.org/deep-learning/relu-activation-function-in-deep-learning/\n",
        "* https://www.geeksforgeeks.org/binary-cross-entropy-log-loss-for-binary-classification/\n",
        "* https://www.geeksforgeeks.org/machine-learning/hyperparameter-tuning-using-gridsearchcv-and-kerasclassifier/\n",
        "* https://www.geeksforgeeks.org/neural-networks-a-beginners-guide/\n",
        "* https://www.geeksforgeeks.org/machine-learning/how-to-handle-imbalanced-classes-in-machine-learning/\n",
        "* https://medium.com/expedia-group-tech/apache-spark-structured-streaming-input-sources-2-of-6-6a72f798838c"
      ],
      "metadata": {
        "id": "mHEhv-ZxAxnQ"
      }
    }
  ]
}